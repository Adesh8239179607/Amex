{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c73e878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import average_precision_score\n",
    "import warnings, gc, os, sys, math, random, time, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c39c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_parquet(r\"C:\\Users\\Adesh Mishra\\OneDrive\\Desktop\\Amex\\data\\train_data.parquet\")\n",
    "test=pd.read_parquet(r\"C:\\Users\\Adesh Mishra\\OneDrive\\Desktop\\Amex\\data\\test_data.parquet\")\n",
    "trans=pd.read_parquet(r\"C:\\Users\\Adesh Mishra\\OneDrive\\Desktop\\Amex\\data\\add_trans.parquet\")\n",
    "event=pd.read_parquet(r\"C:\\Users\\Adesh Mishra\\OneDrive\\Desktop\\Amex\\data\\add_event.parquet\")\n",
    "metadata=pd.read_parquet(r\"C:\\Users\\Adesh Mishra\\OneDrive\\Desktop\\Amex\\data\\offer_metadata.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "468db03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string labels (like \"00001\") to binary 0/1: 1 if any '1' appears, else 0\n",
    "train['y'] = train['y'].apply(lambda x: 1 if '1' in str(x) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a8d636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in train.columns if col.startswith('f')]\n",
    "\n",
    "for col in features:\n",
    "    train[col] = pd.to_numeric(train[col], errors='coerce')\n",
    "    test[col] = pd.to_numeric(test[col], errors='coerce')\n",
    "\n",
    "train[features] = train[features].fillna(-9999)\n",
    "test[features] = test[features].fillna(-9999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a49a0478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User click rate\n",
    "user_click_rate = train.groupby('id2')['y'].mean().rename('user_click_rate')\n",
    "train = train.merge(user_click_rate, on='id2', how='left')\n",
    "test = test.merge(user_click_rate, on='id2', how='left')\n",
    "\n",
    "# Offer click rate\n",
    "offer_click_rate = train.groupby('id3')['y'].mean().rename('offer_click_rate')\n",
    "train = train.merge(offer_click_rate, on='id3', how='left')\n",
    "test = test.merge(offer_click_rate, on='id3', how='left')\n",
    "\n",
    "# User-offer click rate\n",
    "user_offer_click_rate = train.groupby(['id2', 'id3'])['y'].mean().rename('user_offer_click_rate')\n",
    "train = train.merge(user_offer_click_rate, on=['id2', 'id3'], how='left')\n",
    "test = test.merge(user_offer_click_rate, on=['id2', 'id3'], how='left')\n",
    "\n",
    "for col in ['user_click_rate', 'offer_click_rate', 'user_offer_click_rate']:\n",
    "    train[col] = train[col].fillna(0)\n",
    "    test[col] = test[col].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65821bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User's total offers seen\n",
    "user_offer_count = train.groupby('id2').size().rename('user_offer_count')\n",
    "train = train.merge(user_offer_count, on='id2', how='left')\n",
    "test = test.merge(user_offer_count, on='id2', how='left').fillna(0)\n",
    "\n",
    "# Offer's total impressions\n",
    "offer_count = train.groupby('id3').size().rename('offer_count')\n",
    "train = train.merge(offer_count, on='id3', how='left')\n",
    "test = test.merge(offer_count, on='id3', how='left').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adfa11fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before merging\n",
    "train['id3'] = train['id3'].astype(str)\n",
    "test['id3'] = test['id3'].astype(str)\n",
    "metadata['id3'] = metadata['id3'].astype(str)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7453855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all columns except for the offer id\n",
    "meta_cols = [col for col in metadata.columns if col != 'id3']\n",
    "train = train.merge(metadata, on='id3', how='left')\n",
    "test = test.merge(metadata, on='id3', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6375df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['id2'] = train['id2'].astype(str)\n",
    "event['id2'] = event['id2'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57812bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run if 'id4' in event/train/test is a datetime of impression\n",
    "if 'id4' in event.columns and 'id4' in train.columns:\n",
    "    event['id4'] = pd.to_datetime(event['id4'], errors='coerce')\n",
    "    train['date'] = pd.to_datetime(train['id4'], errors='coerce')\n",
    "    last_event = event.groupby('id2')['id4'].max().rename('last_event_time')\n",
    "    train = train.merge(last_event, on='id2', how='left')\n",
    "    train['days_since_last_event'] = (train['date'] - train['last_event_time']).dt.days\n",
    "    train['days_since_last_event'] = train['days_since_last_event'].fillna(999)\n",
    "    test = test.merge(last_event, on='id2', how='left')\n",
    "    test['date'] = pd.to_datetime(test['id4'], errors='coerce')\n",
    "    test['days_since_last_event'] = (test['date'] - test['last_event_time']).dt.days\n",
    "    test['days_since_last_event'] = test['days_since_last_event'].fillna(999)\n",
    "    features.append('days_since_last_event')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b46507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_features = [\n",
    "    'user_click_rate', 'offer_click_rate', 'user_offer_click_rate',\n",
    "    'user_offer_count', 'offer_count'\n",
    "]\n",
    "\n",
    "# Add all metadata columns except the ID (and any columns you've already included)\n",
    "meta_features = [col for col in metadata.columns if col != 'id3']\n",
    "\n",
    "all_features = features + extra_features + meta_features\n",
    "# Remove any duplicates\n",
    "all_features = list(dict.fromkeys(all_features))\n",
    "\n",
    "# Ensure all features are numeric and fill NA\n",
    "for col in all_features:\n",
    "    train[col] = pd.to_numeric(train[col], errors='coerce')\n",
    "    test[col] = pd.to_numeric(test[col], errors='coerce')\n",
    "\n",
    "train[all_features] = train[all_features].fillna(-9999)\n",
    "test[all_features] = test[all_features].fillna(-9999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5f615dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=7):\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(df, k=7):\n",
    "    map_scores = []\n",
    "    for user_id, group in df.groupby('id2'):\n",
    "        actual = group.loc[group['y'] == 1, 'id3'].tolist()\n",
    "        predicted = group.sort_values('pred', ascending=False)['id3'].tolist()\n",
    "        map_scores.append(apk(actual, predicted, k))\n",
    "    return np.mean(map_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7383008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 29723, number of negative: 586408\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.639015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 48631\n",
      "[LightGBM] [Info] Number of data points in the train set: 616131, number of used features: 363\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Fold MAP@7: 0.1090\n",
      "[LightGBM] [Info] Number of positive: 30191, number of negative: 585940\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.472781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 48608\n",
      "[LightGBM] [Info] Number of data points in the train set: 616131, number of used features: 325\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "Fold MAP@7: 0.1026\n",
      "[LightGBM] [Info] Number of positive: 29464, number of negative: 586667\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.595215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 48554\n",
      "[LightGBM] [Info] Number of data points in the train set: 616131, number of used features: 325\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Fold MAP@7: 0.1087\n",
      "[LightGBM] [Info] Number of positive: 28887, number of negative: 587244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.393299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 48584\n",
      "[LightGBM] [Info] Number of data points in the train set: 616131, number of used features: 324\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "Fold MAP@7: 0.1079\n",
      "[LightGBM] [Info] Number of positive: 29939, number of negative: 586193\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.313141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 48580\n",
      "[LightGBM] [Info] Number of data points in the train set: 616132, number of used features: 325\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "Fold MAP@7: 0.1061\n",
      "Mean MAP@7: 0.1068\n"
     ]
    }
   ],
   "source": [
    "X_train = train[all_features]\n",
    "y_train = train['y']\n",
    "from sklearn.model_selection import GroupKFold\n",
    "cv = GroupKFold(n_splits=5)\n",
    "val_scores = []\n",
    "\n",
    "for train_idx, val_idx in cv.split(X_train, y_train, groups=train['id2']):\n",
    "    tr_X, tr_y = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "    val_X, val_y = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "    val_id2 = train.iloc[val_idx]['id2']\n",
    "    val_id3 = train.iloc[val_idx]['id3']\n",
    "    \n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.03,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        class_weight='balanced'  # helps with imbalance\n",
    "    )\n",
    "    model.fit(tr_X, tr_y)\n",
    "    val_pred = model.predict_proba(val_X)[:, 1]\n",
    "    val_df = pd.DataFrame({\n",
    "        'id2': val_id2,\n",
    "        'id3': val_id3,\n",
    "        'y': val_y,\n",
    "        'pred': val_pred\n",
    "    })\n",
    "    score = mapk(val_df, k=7)\n",
    "    val_scores.append(score)\n",
    "    print(f\"Fold MAP@7: {score:.4f}\")\n",
    "\n",
    "print(f\"Mean MAP@7: {np.mean(val_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f80ed9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adesh Mishra\\AppData\\Local\\Temp\\ipykernel_20808\\807136985.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test['rank'] = test.groupby('id2')['pred'].rank(method='first', ascending=False)\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict_proba(test[all_features])[:, 1]\n",
    "test['pred'] = test_pred\n",
    "test['rank'] = test.groupby('id2')['pred'].rank(method='first', ascending=False)\n",
    "submission = test[test['rank'] <= 7].sort_values(['id2', 'rank'])\n",
    "submission[['id2', 'id3']].to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9f13c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
